(9434) I Built an AI Second Brain in 1 Hour (Nate B Was Right) - YouTube
https://www.youtube.com/watch?v=gLaMDOrDGHA

Transcript:
(00:01) Can you build a second brain in one hour? Join me and we&#39;re gonna find out. I&#39;m Eric and this is AI with Eric. And today we are going to build a second brain using AI start to finish in one hour or less. This is all based on a video I watched by Nate B. Jones about how everyone should be building a second brain in 2026.
(00:29)  He claimed it could be done in an hour. I was a little skeptical, so I had to try it myself. I&#39;m going to be doing this in Anvore AI, but you are free to use something like N8N or Zapier like he mentioned. Uh Anvore AI is completely free. I also use Slack, which is again completely free. So what I&#39;m trying to say is you can build a second brain in one hour completely free.
(00:58)  Now, I chose to use Ambore AI because it&#39;s AI first. You can build with AI and I&#39;m going to use AI agents to actually do a lot of the functionality. A lot of people would choose to make things more deterministic. I choose to let AI handle all the work to make the decisions, make the calls, do everything. And that way, the system is actually more resilient.
(01:22) It can handle changes. You can add or remove tables or fields in the tables. Whatever your heart&#39;s content, having it powered by AI will make it more functional, more valuable, and help you organize your life and your work. All right, before we get started, I&#39;ll show you a mermaid diagram I whipped up based on the architecture described by Nate B.
(01:49) We start with the interface which in my case will be Slack but you can use Microsoft Teams, you can use Telegram, WhatsApp or even email if you so choose. You input all your thoughts in a single place. You get your daily or weekly digest in a single place. You fix anything that went wrong in a single place.
(02:13)  And this is not something I&#39;ll be building today because it&#39;s not something Mr. Nate had in his video. Should I choose to use this, I would absolutely add the ability to talk to the agent in Slack and ask questions about my data in the second brain. I feel like that&#39;s a nobrainer, pun intended, and uh something I would definitely do.
(02:38)  So again everything comes in through Slack reading sending it goes through an AI classifier which determines hey do I have enough information to be confident about classifying the data in people projects ideas or administrative work and everything gets logged to the inbox log and if it&#39;s not certain it asks for confirmation or clarification and there&#39;s the daily and the weekly digest that gives you an update and everything you need to do.
(03:11)  Now, I never used Notion or Obsidian because as amazing as they are, I just know I would never keep it up to date. I do plan to at least try using the second brain for a little bit to see how it does and how it helps me. But so far, it&#39;s looking really promising. So, let&#39;s get started. Can we build this second brain? So, first things first, we&#39;re going to create the second brain channel.
(03:40) Call it SB. You would probably make this private in your own case if you&#39;ve got a Slack environment with more than one person, but considering I&#39;m the only person in here, not something I have to worry about. The next thing we&#39;re going to want to do is add our integration. All right, we&#39;ll come over to our workflow where we&#39;re building the second brain and we&#39;ll make sure a few things work first in regards to connecting everything with Slack.
(04:25)  So the first is we&#39;ve got a web hook which can receive things from Slack as they happen. So this is the URL you&#39;d paste in the Slack configuration and I&#39;ll show you that in a second. One other thing we need to be able to do is from this send brain workflow send messages to Slack. We will drag on this HTTP request action.
(04:52)  That will be the template for sending a message to Slack. And let&#39;s configure it with AI just to make it as easy for everyone as possible. Send a message to a Slack channel. And hopefully we&#39;ll get back a configuration that can be used for this. Let&#39;s apply it. And here it is. Now we just need to select a credential and I&#39;ll show you how you can get that in Slack.
(05:30) And all right, let&#39;s put in our channel name SB and give this a test. Let&#39;s look at the history to see if it sent correctly. Oh, invalid arguments. Okay. So, something didn&#39;t work. We can see that this was supposed to be configured as a post request, but it was not. So, easy fix. Let&#39;s try it again.
(06:28) And there we go. It looks like it worked, but let&#39;s go verify. There it is. Easy. And just to confirm the reverse is true, let&#39;s send a message. Now we should see an event pop up here. Actually, two events. So, one for the Anor AI bot message and one for the one I just sent. And we can see the text right here. Test message. Great.
(07:03)  So, we&#39;ve got pretty much everything we&#39;ll need for the Slack integration. And before I move on, let me show you how to configure those things. So, first you would create an application in Slack and you configure it, fill out a few fields, add it to your your Slack environment, and the two things you&#39;ll need is this event subscription link.
(07:30) This is where you paste in the web hook URL that you created here. And you would also need the authentication piece which is in OOTH and permissions right here. I&#39;m not going to click it because I don&#39;t want to have to remember to delete it later. But that&#39;s all you have to do. And that is the credential for configuring sending messages and other actions.
(07:58) All right, let&#39;s get back to building. So, I&#39;m going to follow the loose structure that Nate B provided in the building of this. So, first I&#39;m going to create the tables he defined. And to do that, again, I want to make it really simple for everyone and as quick and as easy.
(08:23)  So, we&#39;re going to use AI to create the tables for us. So, this is an AI agent action. It can autonomously or on demand do pretty much anything you&#39;d like, including writing and running Python code autonomously in response to some input. Uh, all we&#39;re going to do is just give it the table definition tool, and that&#39;ll let it create tables for us.
(08:48) And I&#39;ll start giving it the list of tables I want it to create, and we&#39;ll verify and make sure it works. Trust but verify. Right. So create a table named people. The columns are name, context, follow-ups, last touched, and tags. All of those are text inputs except last touched, which is a date, timestamp.
(09:20) And then create a table called projects. And the columns are name, status, next action, and notes. And then create a new table named ideas. The columns are name, oneliner, notes, and tags. And then create a table named admin. And the columns are name, due date, and status. Those should be texts except for due date which is a date timestamp.
(09:54)  And then create another table called inbox log which has the columns captured text destination record name confidence and created at. Most of those are text inputs. The confidence column should be a number and the created at column should be a date timestamp. So we&#39;re going to review all that and make sure it translated. Okay.
(10:30) Transcribed. I&#39;ll give it a brief description what we&#39;re doing first. This is for the creation of a second brain. And I do actually want to add tags columns to projects and admin. I don&#39;t know why we wouldn&#39;t have those. All right, I think we&#39;re good to run this. Okay, we created five tables, but we should verify that just to make
(11:36) sure everything is as we wanted it to be. So inbox log looks good people. Now next thing we want to do is we&#39;re going to have to capture the brain dump from Slack into the table. So, first we&#39;re going to want to add some sanity checks. I showed before that we actually receive the event for the bot, this workflow, sending a message to the channel.
(12:21) If we&#39;re not careful, that could create an infinitely running loop back and forth between this automation and that second brain slack channel. So, we&#39;re going to check for that first. So, we&#39;re going to add a conditional. And let&#39;s make sure we&#39;re only considering messages from myself because this is private. This is my own second brain.
(12:49) And presumably, you&#39;re not going to get sent the message. So the test message and the user is this. So body event user and I can replay this so that the conditional gets the data. So what we want to do is make sure the user sending the message is my ID so we can get the data and you see all of the actual data right here and you can autocomplete it.
(13:46)  Body eventer there. This should now only work when I&#39;m the one that sent a message to that channel. And we can verify that by just adding the true condition and the false condition. So, we&#39;ll send another test message and we should see this run and go to the false condition. And then, yep, there it is.
(14:36)  Now, I&#39;ll go back and send another message. And we want to verify it comes in. Yep, here it is. So, that&#39;s functional. All good. Now, we can continue with the building. The next step and I will consider this the most difficult andor fiddly is we need to actually extract and classify the message which table it should go into the confidence.
(15:11)  Uh so that is probably going to be the trickiest part and we&#39;ll we&#39;ll see what we can get working. So once again, we&#39;re going to use an AI action, AI agent, and we&#39;re going to have to think about the prompt a little and what exactly we want it to do, what the output&#39;s going to be, and then what the next actions are.
(15:38) So, let&#39;s just give it a whirl, see what happens. You are a helpful and concise AI analyst. You are going to look at the input text and return the following destination which will be one of people, projects, ideas or admin and record name which is the subject of the message and confidence. which is a number representing your confidence in what you are providing.
(16:34) Now we are going to give it the input text and And let&#39;s verify this and return the following destination. destination, project ideas or admin record name. Okay, now we can actually send something to our second brain and see what happens.
(17:42) That with Sarah about the upcoming sales project. Let&#39;s see how it classified our brain dump destination people record name Sarah confidence one that is actually perfect for what we&#39;re doing. So one thing I do need to add though is the confidence should be between zero and one.
(18:24)  So, I&#39;ll just go back and add that to make sure. There. I think that should cover it. Next, we want to store the information in the inbox, which is going to capture all incoming records. So, I could do this little table action and create a row and select one of the tables, but I would like to use AI to do as much of this as possible to make sure that it&#39;s resilient to any changes and it&#39;s more like an actual human assistant doing this work for you as your second brain.
(19:14) So, we&#39;re going to use another AI agent action and we are going to set it up to our GLM 4.7 provider and we&#39;re going to give it the data tools. This is a list of tools that lets the agent explore what tables exist as well as you know list filter and create data. So now we want to do a couple things. First we want to add it to our inbox and then we want to actually add it into one of the specific tables we created.
(19:59) So let&#39;s see if we can get it to do both in one prompt. First add a record to the inbox log and the captured text is placeholder. The destination is placeholder. The record name is placeholder. The confidence is placeholder. and the created at is placeholder. So, I&#39;m going to go back and update all the placeholders with the actual data.
(20:48) And let me take a step back. Instead of referencing the very specific data, instead I&#39;m just going to give it everything that it got from the AI agent in the previous step. So we&#39;ll call this classify agent and give it the input data. The response is what we need. And let&#39;s update the prompt. Use the input data to captured text is the only one we want to
(22:08) do the original supplied value from Slack that I the sender submitted. And the next thing we want to specify created at. And this is a ginger template that just inserts the current timestamp. So we can verify this is what it actually resolves to. No problem. The rest of the data is supplied in the
(23:17) input. This is looking good. Now, one other thing we&#39;re going to want to do is make sure the agent has the understanding of the tables, the structures, their column names, so that it can do what it needs to both in understanding ing and contextualizing what we&#39;re telling it as well as being able to actually create the row in the table.
(24:12) So I&#39;ll say first get a list of all the tables then then finally probably the trickiest part for the agent is this next bit which is adding it to the correct table with all the correct information. So let&#39;s see based on the name of the destination add a row to the correct table with the correct values for the correct columns.
(25:01) Again this is based on the input data and the list of tables for the second brain project you received. Let&#39;s change this in the first step. Okay. It would be great if all of this works on the first shot, but let&#39;s give it a whirl and see if it does. I&#39;ll give it a very new thing just to test the confidence rating again and see how it&#39;s functioning and see if that final step actually works.
(25:48) The sales project MVP is due January 27. All right, let&#39;s see how our agent actually did in, you know, working on the second brain stuff for us. Okay. Destination projects, sales project, MVP, good. Competence 0.95, all good. classification looks pretty good. Let&#39;s check the actual data storage. So, what tasks did it do? Added a record to the inbox log. Looks good.
(26:41)  Added a row to the projects table. Looks good. Let&#39;s actually verify that. Uh we can just look at the tool trace and say, okay, it listed the tables. Good. It has what it needs. and add a row. Add a row. Yeah, looks good. But let&#39;s verify. So, inbox log. All right. Sales project MVP looks good. And projects. Sales project MVP status.
(27:16) That&#39;s something we&#39;ll probably need to add. agent could have inferred that some kind of status because obviously it&#39;s probably not done or this could just be a takeaway for using second brain is having that information in the message ourselves. I don&#39;t want to solution it right now, but if I recall from Nate&#39;s video, there was some pretty specific instructions about what you should say to the second brain in that you need to give it specific actions.
(27:57)  So, I told it that this project was due, but I didn&#39;t mention its status or what action or actions were necessary. So, it could be a bit of both. a improved way of interacting with the second brain and what to tell it as well as actually asking the agent to classify or give it a inferred status and next actions and tags. No, I think we would just want to specify any tags in the actual message if we wanted to have any.
(28:26) So, let&#39;s get back to building out the second brain. The next two parts we need to add first is letting the user know if something needs review. So if the confidence score is below a certain threshold and the second part of that is letting the user fix or make updates to that particular issue.
(29:03)  So we&#39;ll start by checking the comments and sending a Slack message if it&#39;s below a certain number. All right. So we need to add the check if the confidence is too low. So let&#39;s do that real quick. Again, let AI do all the work for us. We just need to give it the send a Slack message tool. If the confidence rating is below 0.
(29:46) 60, send a message on Slack asking for clarification of the message and we&#39;ll provide the raw message we received. And we will put that in quotes and give a brief explanation of the confidence score and what we need. clarification on. All right. Now, the fun part is coming up with something we can send that will result in a low confidence score.
(30:55) Hugga in the boouga. So, let&#39;s see what kind of confidence we get from that. And this might be a good sanity check to make sure we&#39;re not getting garbage. Okay. Confidence 0.4. That is exactly what we want to see. Did it send the message? Okay, let&#39;s rerun that and the bogga and it should come back and tell us, hey, this is no good.
(31:49) So, looking good, but did it actually send the message? Oh, message sent. There we go. Okay, so the next step would be actually receiving and conducting the fix. So the suggestion in Nate&#39;s video was to do it in a thread. So we would respond in a thread here and actually give it the clarification. But before we actually try this, we need to add the handling in the second brain workflow. So, let&#39;s go back.
(32:32) And I think the easiest way to do this is to just get a threaded message and see what it looks like in the workflow in Andor Builder and do it from there. So, I&#39;m going to disconnect all of this entirely and respond to a thread. And then now we can see what a thread actually looks like and check for that condition and process it.
(33:07) So this is what it actually is and this is what we want to look for this thread timestamp. So, we&#39;re going to add a check to see if what we received is from a thread. Uh, it&#39;s a good thing I disconnected it because it looks like it actually tried to run one time from the uh failed response. So, we got a message uh a low low confidence alert for the low confidence message, which is why we disconnected it, but one slipped through. No problem.
(33:53) We are going to add a new conditional check. To do that, let&#39;s rename this one and so we know what it&#39;s for. As before, we&#39;re adding a second one. Checker thread. I think it was thread_ts. Let me double check. Event thread_ts. Okay. And not null. So now we are checking if it&#39;s
(34:59) got that thread ts property. So we know it&#39;s a threaded message. If not, we will just go down the workflow. We had already built that path. And if it is a thread, that&#39;s where we need to handle the actual. And I think the easiest thing we&#39;re going to do is just copy these two agents and maybe just slightly adjust them.
(35:36) Let&#39;s see what we&#39;ve got. One thing we can do to make sure this agent behaves exactly like you want is give it the full context of the thread. So to do that, we want to get the messages in a slack thread. So we&#39;ll configure this with AI. Get all of the messages in a Slack thread and we&#39;ll see what it comes back with.
(36:09) See if it&#39;s correct. Should be okay. It&#39;s pretty straightforward. Conversation replies. Yep, that looks good. Give it the credential. Don&#39;t need these headers. And it did not copy the body over. That&#39;s unfortunate. Let&#39;s go over to the documentation channel and TS. All right, no problem. channel and TS.
(37:30) It&#39;s not connected to anything. Selected context. All right, let me disconnect this and we&#39;ll replay the last threaded message. We want the thread which is this one. All right. Get threaded messages invalid arguments. Let&#39;s check one more time. Event channel as an extra debug step. I want to know exactly
(38:34) what this payload is. So, I&#39;m going to move this over here. And now let me run this. Did it get it? It did. So now we can see the message history. And we will pass in the complete message history to our agent. Give it the full context.
(40:05) And now we want to tell it to redo the classification with using the context and the updated message. All right, let&#39;s disconnect this and give the whole thing a run. Let&#39;s delete these old messages. The project code name is Ugga and the deliverable is a PowerPoint. All right. Let&#39;s check the workflow.
(41:49) It has the messages. And let&#39;s check the agent. Uh, nope. This was not what we wanted. All right, one more time. classification. It&#39;s actually got the messages. What did it say? Destination projects confidence record name. Okay,
(42:52) now we can hook it up to the store data agent. The only difference is this time we do not want it to do the raw input log. So, now that we&#39;re here and I&#39;m thinking about this, actually, what we can do is I was going to say we could delete or read the row or update the row, but it gets a little complicated because we&#39;re not using a primary key or a unique unique value to identify the row other than the native ID behind the scenes.
(43:43)  So what we can is come here to the store data agent and we are not going to create the actual second row. We&#39;re going to leave in the input data but then we&#39;re going to take this part. Now all we&#39;re doing is creating the inbox record. Then we are going to go here to the confidence check agent and move that last bit here.
(44:28) And we want to give it the ability to add a row. Now in our confidence check agent we give it the list tables tool and the add row tool and just add this little bit I copy pasted if the confidence is above 0.60 6. Then get a list of the tables and yada yada yada add the data just like we had in the store data agent.
(45:01) And one more bit is on this path for storing the data. We want to remove the inbox log. Okay, I think we&#39;ve got the complete workflow done and we can give it a test once more. We&#39;ll give it a new low confidence thing. And if everything works as expected, we should get a another one of these low confidence alerts.
(45:54)  Let&#39;s see how it classified. It should come down this path first. confidence one. Okay. Great. That worked as expected. Now, let&#39;s try the fix. I&#39;m meeting with Reeba and going over data labels. And we should finally have a functioning fix to this horrible message to our second brain. Let&#39;s see how it did. Task completed successfully.
(46:55)  That&#39;s a good sign. Listed the tables. added the row and let&#39;s actually look at the data in the table. Okay, so couple things here. We have the name populated correctly. Great. But we don&#39;t have context follow-ups or less touched. Now follow-ups, we didn&#39;t really specify anything to follow up on. So, okay, that&#39;s expected context.
(47:30)  This is missing. This is needed. And last touched the there are timestamps on the table behind the scenes, so we don&#39;t necessarily need that, but we should probably add it for good measure. So, we can fix these things pretty easily. Uh, in the store data agent, we just want to give it the original context. which is the message.
(48:09) And we&#39;re going to need the time stamp. Okay, that should do the trick. Let&#39;s give it a test run one more time. Uh maybe hundth more time. Let&#39;s go check out the workflow. Completed successfully. But let&#39;s look at the raw data. All right, here we go. We&#39;ve added the context. We&#39;ve added the last touch.
(49:07) So, I think the final thing we need to do for the second brain as described by Nate is the digest. All right. To do the daily digest, we will just use another nifty AI agent action. Let&#39;s call it daily digest. And what are we going to say? List all the tables. Then filter the data for the people, projects, ideas, and admin table by updated date in descending order.
(49:57) Okay, let me review this. That looks good. Expected output. Provide a two to three sentence summary of all the most important items that I need to follow up on. All right, let&#39;s give this our table tools and see how it does. It&#39;s running the tools, getting all the table data. All right, let&#39;s see what it says.
(50:53) I have an upcoming meet up with Reeba. Great. Yep. Okay. Immediate priority sales project MVP due January 20th. Okay. Perfect. So, this worked about as well as I could expect given uh the short amount of time we built this in. And so, I ran that manually. But what you can do here is go down and enabled scheduled execution.
(51:26) run daily at 9:00 a.m. And there you have it. We&#39;ve built a second brain allin-one platform. We can interact with it through Slack or whatever medium you&#39;d like. Teams, email, Telegram, and we&#39;re storing the data, analyzing it, searching it, and doing a daily digest all with AI. Thank you for sticking around so long if there is anyone that actually did.
(52:00)  And I hope to see you in the next one. Bye.


Transcript made by Scripsy.ai â€“ AI-powered summaries and accurate transcriptions for YouTube videos