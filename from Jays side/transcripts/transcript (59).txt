(10038) OpenClaw + BMAD: How I Ship SaaS With Autonomous AI Coding Agents - YouTube
https://www.youtube.com/watch?v=lXKlFlDFFMc

Transcript:
(00:00) Imagine waking up, checking your phone, and seeing that your AI agent has been coding all night, committing to GitHub, deploying to Versel, drafting marketing emails, and even integrating customer feedback. In this video, I&#39;m going to show you exactly how I set up autonomous AI agents to build SAS application using two frameworks.
(00:21)  Open Claw for long-term agent orchestration and the BM ad method for structured software engineering. I&#39;ll walk you through the architecture, the integration, what failed, what works, and the exact setup you can replicate today. Before we get into the setup, let me quickly explain the two pieces of this puzzle.
(00:44)  Openlow is an open- source AI agent platform. Think of it as a supervisor that can run sub agents, maintain long-term semantic memory, browse the web, manage files, and connect to tools like Discord, Telegram, whatever. The key feature is the memory. Unlike a normal cloud or chat GPT session that forgets everything after the context window fills up, OpenClaw remember project goals, architecture decisions, past mistakes across sessions across days.
(01:15)  And because it has full control over the machine it runs on, it can do anything you would do. Run commands, deploy code, all exposed through a gateway you interact with via browser or messaging channels. The BMAD method stands for breakthrough method of agile AIdriven development. It is a structured approach to AI assisted software engineering.
(01:41)  It mimics how a real team builds software. You have an architect agent, a product manager, a scrum master, developers, reviewers. Each role has a specific system prompt and they follow a real workflow. P Hardy first, then architecture, then sprint planning, then coding, then review. It&#39;s not just build me an app, but the full engineering life cycle prompted properly.
(02:08)  The method is actively maintained and covers more than just implementation. There are workflows for architecture, testing, documentation, you name it. The idea is simple. Open claw replaces me as the operator. The BMAD method replaced the chaos of unstructured prompting. Now let&#39;s discuss how to combine these two tools to develop SAS autonomously.
(02:31) Here is the full architecture. There are three layers. The first layer is the public internet. This handles the heavy lifting cloud for inference. I use a subscription token not API keys which is almost 10 times cheaper. You can also use other models. Open Claw supports multiple providers, but I strongly recommend that you pick Opus 4.
(02:54) 6 or Codeex. Older models performance are just not worth their price. On top of the LLM inference endpoint, there&#39;s GitHub for version control, superbase for the back end, and the versel for hosting. Since I am strictly building SAS, these are the only boundaries the agent needs, but you can swap any of these for your own stack.
(03:17)  And I&#39;m now expanding this further, giving the agent access to MCP servers and marketing APs like Reason, so it can handle the business side too. Email campaigns, social posting, customer outreach. That&#39;s still experimental, but the infrastructure supports it. The idea is to eventually have the agent not just build a product, but also run it.
(03:38)  The second layer is a VPS. This is where the agent lives. It&#39;s a cheap 12 GB RAM VPS. Nothing crazy since inference is external. Open claw runs here with its gateway. It has access to the file system, semantic indexing for memory and the ability to spawn sub agents. It browses the web, checks logs, and acts autonomously.
(04:03)  You connect to it via SSH tunnel and optionally through Discord or Telegram if you want to interact from your phone. Setting up the Discord connection is straightforward. You create a bot token on the developer hab portal, link it to open claw and the agent configure pairings such that you can dehem him. I strongly recommend to avoid invite the bot to a public server whereas anyone could interact with it.
(04:28) The third layer is just the command center into the gateway to monitor, review output and steer when needed. I don&#39;t run any heavy compute locally. Think of it as remote control. Now, two important things before we move on. First, the credentials. Create dedicated accounts for the agent.
(04:52)  Separate GitHub account, separate superbase account, separate versal account, full permission, but on its own scope. For GitHub specifically, I prompt the agent to create repositories, keep them private, and invite my main account as an admin reviewer. This gives you clean observability. In my setup, I can see every commit, every PR without digging through SSH logs.
(05:15)  It&#39;s much better than monitoring log files manually. Second disclaimer regarding security. Don&#39;t expose the gateway publicly without authentication. Harden your VPS, use SSH keys, and keep the agents credentials scoped to what it actually needs. I&#39;ll link a security checklist alongside the setup scripts in the description.
(05:39) A security researcher has kindly provided the community with a hardening guide and a deployment script. So use it. Open CLO is far from being secure and many bridge are already being exploited. Now that infrastructure is ready, let&#39;s talk about the actual method to automate software engineering using the BMAD method with open claw.
(06:02) First, let me save you some time and tell you what failed. The naive approach was to install OpenClaw locally and have it run the Cloud Code CLI, which would then trigger BMAD agents. So, you had me talking to OpenClaw, talking to Cloud Code, generating a BMAD prompt, which talked to Cloud again, then passing it back.
(06:25)  It caused massive token duplication and memory leaks. The prompts were too large, and it led to context overflow. Complete nightmare. I ran two experiments with variation of this approach. In the best case, I gave OpenClaw the full B mad master prompt with meta instruction like every 30 minutes, remind yourself of your long-term goal.
(06:46)  It actually found an idea on its own, created requirements and deployed something to the VPS. So, the potential was clearly there. But after about 10 steps, the BMAD master node crashed from memory overflow. The agent started improvising, loading its own prompts, abandoning the BMAD structure, falling back to unstructured coding.
(07:11)  The second attempt crashed even earlier. Same root cause every time. The wrapper approach generate too many tokens and kills the context. So I needed a fundamentally different integration. Here&#39;s what actually works. Instead of running BM AD through a wrapper, I extracted the individual BMAD RO prompts, architect, scrum master, developer, reviewer, and save them as files that open claw can natively load as sub aents.
(07:42)  There is nothing really difficult here. Just load the steps and workflow prompt into sub agent instantiated by open claw. Now, if you are like me and have used BMAD in VS Code in the past, you probably used it with cloud code. Here it&#39;s different. Open claw doesn&#39;t need to call cloud code to get BMAD behavior.
(08:01)  It just needs the right system prompts loaded as sub aents in its own framework. No wrapper, no extra LLM layer, no token duplication. Now that everything is ready, here is the main steps that you must follow in order to get a decent result. Usually I handle the initial phase myself from the brainstorming to the highle idea.
(08:23)  The first two or three steps of the BMAD method, product requirements, architecture, direction, technology choices. This takes maybe 30 minutes of my time. Then I hand it to the agents. This prevent hallucination and provide clear foundations. Open club picks up from there. It spawns the appropriate sub aents following the BMA structure.
(08:49)  Sprint planning, then implementation, then review. I let it run in batch of about five steps at a time. After each batch, I check the output correct course if needed and let it continue. Once you have covered the first print for authentication, billing and important features, you can consider giving more freedom to open claw while it still has access to the PRD and architecture ducks through long-term memory.
(09:14)  That&#39;s the magic. It can always refer back to the project goals without eating up the context window. For the project where I dialed this in, I was building a SAS that generates slide decks from company templates. Using this sub agent method, the result was nearly production grade. The agent created the architecture, built the front end, connected the back end, deployed it.
(09:41)  I&#39;m actually looking at releasing it soon. I am also currently using it to develop marketing automation for the SAS I intend to build. This means connecting it to social media accounts, advertisers, etc. I even created a dashboard using the same method and which is providing me feedback both on the dev side and the marketing side.
(10:02)  Finally, here&#39;s the key findings after running this setup for a couple of weeks. First, don&#39;t treat it as fully autonomous. It works best in 2 to three hour burst. If you leave it running 24/7 without guardrails, it hallucinates or gets stuck in loops. You need a governance layer. That governance layer is either you reviewing every few hours or it&#39;s the B M A DP RD documents themselves which give the agent strong direction he can access anytime through long-term memory.
(10:35)  Second, the initial prompt framing is everything. If you give vague instructions, you get vague output. If you give a solid PRD with clear scope, technology choices, and acceptance criteria, the output quality is genuinely impressive. Think of it like onboarding a real developer. The quality of the brief determine the quality of the work.
(10:58)  Third, use the subscription token, not the API. Open Claw lets you link your cloud subscription directly instead of using API keys. It&#39;s significantly cheaper for sustained usage. I started with the 5x plan and upgraded from there. Fourth, observability through Git is underrated. Having the agent commit to GitHub with its own account means I can review its work like I&#39;d review a junior developer PRS. It&#39;s much cleaner than SSH logging.
(11:26) Set this up from day one. Fifth, limit the scope. I&#39;m building SAS exclusively, so the agent always uses the same stack. Next.js, Zuperbase, Versal. This limits hallucination because the patterns are repetitive and well doumented. So to sum it up, Open Club provide the long-term memory and agent orchestration.
(11:51)  The BMA method provides the engineering structure. You run them on a cheap VPS, give the agent its own tool accounts, and steer it like a CTO reviewing a developer&#39;s work. It&#39;s not perfect, and it&#39;s not magic, but it is a legitimate force multiplier. Since building this setup, I&#39;ve used the same core approach to build an ML powered application for a startup an AI that trains another AI for different projects, different stack, different constraints.
(12:19)  That&#39;s going to be the next video because I want to show you this method isn&#39;t just a one-off. It&#39;s repeatable. If you want the modified BAD prompt files I use for direct integration with OpenClow, let me know in the comments. setup scripts, config file, and the security checklist are all linked in the description.
(12:41)  I also have a Discord where a few of us are experimenting with this exact workflow in the link below. If you&#39;re building with AI agents and want to go deeper, come join us. Like and subscribe if this was useful. I&#39;ll catch you in the next one.


Transcript made by Scripsy.ai â€“ AI-powered summaries and accurate transcriptions for YouTube videos