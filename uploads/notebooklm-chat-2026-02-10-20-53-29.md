---
exported: 2026-02-10T02:53:29.092Z
source: NotebookLM
---

# NotebookLM Conversation

Exported: 09/02/2026, 20:53:29

---

## User

# How I Get Unlimited Leads Using Claude Code (For Cold Email)

1 source

The provided source explains how a lead generation firm transitioned from third-party platforms to a **proprietary, high-speed system** developed using **AI-assisted coding tools** like Claude Code. By utilizing **"vibe coding,"** the team built custom infrastructure that processes millions of leads in seconds at a fraction of the cost of traditional software. The narrative details a **specialized tech stack** involving GitHub, Railway, and various AI layers to scrape data, enrich contacts, and automate campaign management. This internal system allows for **unprecedented scale**, enabling the company to send millions of cold emails while maintaining high deliverability and validation rates. Ultimately, the text highlights how **non-technical users** can leverage modern AI to outpace market-standard tools and solve complex operational bottlenecks.

Wednesday, February 4

Explain the technical stack including Railway, GitHub, and worker robots.

The technical stack described in the sources is a proprietary, high-volume lead generation system "vibe coded" primarily using **Claude Code**. This system was built to replace existing tools like Clay, which could not handle the required scale of processing millions of leads quickly,.

The core components of this stack include:

**GitHub (Code Storage and Syncing)** GitHub functions as the central "cloud storage system for code," ensuring that all work is organized and backed up so nothing is lost. It serves as the bridge between the code generation and deployment.

• **Workflow:** The code sits inside GitHub. When **Claude Code** pushes new updates to GitHub, the system is set up to sync with **Vercel**, which hosts the front-end dashboards and visual interfaces. This allows the team to preview changes and monitor campaigns visually.

**Railway (Backend Infrastructure)** **Railway** acts as the heavy-lifting infrastructure that hosts the system's "workers" and databases,.

• **Cost and Scale:** Railway is praised for being extremely cost-effective, with the lead processor instance costing approximately $20 per month. Despite the low cost, it offers massive processing power, capable of handling up to 12 million items per hour in specific instances.

• **Databases:** Railway allows the team to host **Postgres databases** where all lead data, validation results, and enrichments are stored. (Note: The team is also exploring migrating from Postgres to **Convex** for better real-time data handling).

**Worker Robots (Processing Agents)** The "workers" are deployed directly to Railway.

• **Function:** They are described as "**little robots that process our leads 247**".

• **Concurrency and Speed:** The system runs approximately 50 of these workers simultaneously. This parallel processing is what enables the system to achieve extreme speeds, processing **272,000 leads per second** (equivalent to 1 million leads in 5 seconds),.

• **Reliability:** Unlike third-party platforms where an error affects thousands of users, if these custom workers error out, the team can simply fix the specific issue immediately, optimizing the system strictly for their own use.

**Creation Tool (Claude Code)** The entire system was built without the creators writing a single line of code themselves. They utilized **Claude Code** (and previously Cursor) to write the software, utilizing natural language prompts to build scrapers, enrichment tools, and the core processing architecture,.

Today • 8:48 PM

how would I make this using claude code without coding anything?

Based on the sources, you can build this system without writing code by using a method the creators call "vibe coding" with **Claude Code**. This involves using natural language prompts to instruct the AI to write, manage, and deploy the software for you.

Here is the step-by-step approach to building this system using Claude Code:

1\. Adopt the "Vibe Coding" Workflow

You do not need to learn syntax or programming languages. Instead, you need to articulate clearly **what** you want to accomplish and ask Claude Code to execute it.

• **Interact via Prompts:** You treat Claude Code like a technical partner. For example, if you want to integrate a tool, you would type: _"Go get the API for Lead Magic and can you walk me through how to set this up?"_.

• **Follow Step-by-Step Instructions:** Claude Code will often provide the code and tell you exactly what to do next. The source emphasizes that you just need to be "willing to learn" and ask "really good questions".

2\. Set Up the Core Infrastructure

You will use Claude Code to orchestrate three main services. You don't need to manually configure these; you ask Claude to create the code that utilizes them:

• **GitHub (Storage):** Ask Claude to set up a GitHub repository. This acts as your "cloud storage system for code," ensuring everything is backed up.

• **Railway (Backend):** Instruct Claude to create "workers" (described as little robots) and deploy them to Railway. These will handle the heavy processing, like running 272,000 leads per second.

• **Vercel (Frontend):** Ask Claude to build visual dashboards ("front-end components") and deploy them to Vercel. This allows you to see your campaign data visually. The system is set up so that whenever Claude pushes new code to GitHub, it automatically updates the Vercel dashboard.

3\. Start Small with One Pain Point

Do not attempt to build the entire 272,000-lead-per-second engine on day one.

• **Pick a Specific Bottleneck:** The creators recommend starting with the thing slowing you down the most. For them, it was row limits and processing speed.

• **Build Single Tools:** Start by asking Claude to build one specific tool, such as:

    ◦ A **Google Maps scraper** that works zip code by zip code.    ◦ An **automated cleaner** that deletes old leads from your email sending platform (like Instantly) to save money.    ◦ An **Executive Summary system** that analyzes your campaigns and sends you a report.

4\. Create and Manage Databases

Instead of manually creating spreadsheets, ask Claude to set up databases for you on Railway or Convex.

• Instruct Claude to create a **Postgres database** (on Railway) or a **Convex** instance to store your lead data, validation results, and enrichments.

• This allows you to store millions of records (like the 50 million leads mentioned in the source) without the row limits found in tools like Clay or Excel.

5\. iterate and Expand

Once the core is running, you can "vibe code" additional features by describing the logic you want:

• **Enrichment Logic:** Ask Claude to build logic like, _"If we don't find a valid email for \[Name\], look for their personal email or check if they have a second job"_.

• **Ad Library Scrapers:** Ask it to build scrapers that find companies running ads on Google or LinkedIn to identify warmer leads.

**Key Takeaway:** The "code" resides in GitHub, but you never have to write it. You simply tell Claude Code what you need, and it manages the creation and deployment of the software to Railway and Vercel.

What data is included in the AI-generated executive summary reports?

Based on the sources, the AI-generated executive summary reports provide a daily analysis of campaign performance to help the team identify what they should be focusing on.

The data included in these reports covers:

**1\. quantitative Performance Metrics**

• **Campaign Snapshots:** A quick view of randomly selected clients (e.g., 15 at a time) to gauge general performance.

• **Success Ratios:** Specific data on **email-to-lead ratios** and the **number of meetings generated** from specific campaigns.

• **Average Rates:** An overview of average performance rates across the system's scale.

**2\. Deep Copy Analysis** The system analyzes the actual content of the emails by matching templates to a schema. It breaks down and categorizes:

• **Subject Lines:** Identifies which types are winning for specific audiences.

• **Hook Types:** Analyzes the opening hooks and calls-to-action (CTAs).

• **Messaging Categories:** Evaluates body messaging, curiosity statements, and social proof categories.

• **Personalization:** Reviews the AI personalization elements used in the copy.

**3\. Strategic Insights & Recommendations**

• **ICP Categorization:** The system categorizes the Ideal Customer Profile (ICP) for every client.

• **Historical Comparison:** It looks at sends from the past week as well as all historical data to identify trends.

• **Actionable Advice:** It generates specific recommendations, such as identifying that a certain type of subject line is working best for a specific ICP and suggesting what to do next.

The ultimate goal of this system is to eventually allow the AI to programmatically create new campaigns based on this data, ensuring that the highest performing copy strategies are applied to the right industries automatically.

How does the system use AI to analyze specific messaging hooks?

Based on the sources, the system uses AI to analyze messaging hooks by breaking down email copy into structured data components and correlating them with performance metrics. Here is how the process works:

**1\. Schema Matching and Categorization** The system takes every email template sent and "matches it to a schema" to deconstruct the text into specific variables rather than treating it as a block of text.

• **Hook Identification:** It specifically isolates the **"hook type"** used in the email to categorize how the message opens.

• **CTA Analysis:** It analyzes the ending of the message to determine if the hook functions as a Call to Action (CTA).

• **Element Breakdown:** Beyond just the hook, it categorizes related elements that support the hook, such as **curiosity statements**, **social proof categories**, and **body messaging categories**.

**2\. Contextual Performance Analysis** Once the hooks are categorized, the system cross-references them with the campaign's quantitative data (email-to-lead ratios and meetings generated).

• **ICP Correlation:** It categorizes the Ideal Customer Profile (ICP) for every client to see which hooks work for specific roles. For example, it seeks to identify exactly what copy elements are required to get the "highest multiplier on campaign efficacy" for a specific target, such as a director of marketing at a paper manufacturing company.

• **Trend Identification:** It looks at historical data and recent sends to identify winning patterns, such as determining that a specific subject line or hook style is currently performing best for a specific industry.

**3\. Automated Recommendations** The ultimate output is a set of actionable recommendations. The system will report findings like, _"Hey, for this ICP, this type of subject line \[or hook\] are winning based on this, here's what we should do next"_. The goal is to eventually enable the system to programmatically create new campaigns that automatically select the best-performing hooks for a given audience.

Can this reporting system automatically launch new high-performing email campaigns?

Based on the sources, the short answer is **not yet fully, but that is the explicit goal the team is working toward.**

Currently, the reporting system generates detailed **recommendations** for human operators, but the fully automated programmatic creation of new campaigns based on those insights is described as a feature they are "putting together" and aiming to launch "very very soon".

Here is the breakdown of the system's current versus future capabilities regarding campaign automation:

• **Current Capability (Insights & Recommendations):** Right now, the executive summary system analyzes historical data and recent sends to generate actionable advice. For example, it will report: _"Hey, for this ICP \[Ideal Customer Profile\], this type of subject line is winning... here's what we should do next"_. It identifies specific winning elements (hooks, curiosity statements, etc.) so the team can manually implement them.

• **Future Capability (Programmatic Launch):** The creators explicitly state that they want to get to a spot where the system takes these performance insights and **"programmatically creates campaigns"** automatically. The vision is for the AI to determine the highest efficacy copy for a specific target (e.g., a marketing director) and instantly generate and launch the campaign without human intervention.

• **Existing "Autopilot" Features (Lead Management):** While the _creative_ strategy isn't fully automated yet, the **logistics** of keeping campaigns running are. The system currently monitors lead volume; when a client runs low on leads, it automatically deletes old leads from the sending platform (to save on storage costs) and uploads new validated leads to keep the campaign active.

How do the ad library scrapers find warmer sales leads?

Based on the sources, the ad library scrapers find warmer sales leads by systematically monitoring the ad libraries of **Google and LinkedIn** to identify companies that have been running ads within a specific timeframe, such as the last 30 to 60 days.

These leads are considered "warmer" than standard leads for the following reasons:

• **Proof of Budget:** Companies running ads have a budget specifically allocated for client acquisition, unlike companies that are not investing in growth.

• **Active Intent:** The presence of active ad campaigns signals that the company is actively trying to grow right now.

• **Volume Filtering:** The system can filter lists by how many ads a company is running, allowing the team to prioritize businesses with significant ad spend and activity.

What logic keeps clients from running out of leads?

Based on the sources, the system uses an **"automatic refill" logic** to ensure clients never run out of leads while simultaneously optimizing costs. This process runs on autopilot and involves the following steps:

**1\. Volume Monitoring and Cleanup** The system continuously monitors the lead volume within the email sending platform (specifically **Instantly**, though the team is migrating to **Email Bison**).

• **Trigger:** When a client's campaign gets low on leads, the system initiates a refill process.

• **Cost Optimization:** Before adding new data, it automatically deletes old leads from the sending platform. This is critical because platforms like Instantly bill based on the number of stored leads. By removing processed leads, the system prevents the client from being charged for storing data that is no longer being emailed.

**2\. Automatic Uploading** Once the old data is cleared, the system automatically uploads a fresh batch of validated leads directly into the campaign.

• **Seamless Transition:** This "automatic refill" ensures that the campaign continues without interruption, effectively putting the entire lead generation process on "autopilot".

**3\. Internal Data Reservoir** This logic is supported by a massive proprietary backend:

• **Private Database:** The system draws from a private database containing nearly **50 million leads**. Because every lead ever pulled is cataloged, the system rarely needs to buy new data, instead recycling and repurposing existing contacts that haven't been contacted for that specific client.

• **Vendor Optimization:** If new data is required, the system analyzes which data vendor (e.g., Lead Magic vs. Wiza) provides the most valid data for that specific industry (ICP) in real-time. This optimizes the "waterfall" process to ensure the highest quality leads are fed into the system.

How does the system calculate campaign performance multipliers?

Based on the sources, the system calculates "campaign performance multipliers" by analyzing the correlation between specific **structural elements of email copy** and **campaign outcomes** (such as meetings booked or leads generated) for specific **Ideal Customer Profiles (ICPs)**.

Rather than using a single mathematical formula, the system identifies the "multiplier" by determining which precise combination of variables creates the highest efficacy for a specific audience.

Here is the step-by-step process used to determine these multipliers:

**1\. Deconstructing Copy via Schema Matching** The system does not view an email as a block of text. Instead, it "matches it to a schema" to break down every template into specific, analyzable variables. These variables include:

• **Hook Types:** The specific style of the opening sentence.

• **Body Messaging:** The categories of arguments or value propositions used in the main text.

• **Social Proof Categories:** The types of evidence or case studies cited.

• **Subject Lines:** The specific structure or angle of the subject line.

• **Curiosity Statements:** Phrasing designed to pique interest.

• **Call to Action (CTA):** Whether the hook serves as the CTA or if a specific closing question is used.

**2\. Categorizing the Audience (ICP)** Simultaneously, the system categorizes the **Ideal Customer Profile (ICP)** for every client and campaign. This allows the system to differentiate between what works for a "Director of Marketing at a paper manufacturing company" versus a different role or industry.

**3\. Correlating Variables with Historical Data** The system analyzes all "sends from the last week plus all of our historical data" to see how specific variables perform for specific ICPs.

• It looks at quantitative metrics like **email-to-lead ratios** and **meetings generated**.

• It identifies patterns where specific combinations (e.g., _Subject Line Type A_ + _Hook Type B_) consistently outperform the average for a specific audience segment.

**4\. Identifying the "Multiplier"** The "multiplier" is essentially the identified **winning strategy** that drastically increases results compared to the baseline. The system generates an executive summary that highlights these findings, such as: _"Hey, for this ICP, this type of subject line is winning... here's what we should do next"_. The goal is to programmatically apply these "highest multiplier" elements to future campaigns to maximize efficacy automatically.

How could the system eventually programmatically create new campaigns based on data?

Based on the sources, the system aims to eventually programmatically create new campaigns by transitioning from **reporting insights** to **executing actions** automatically.

Here is how that process is designed to work:

**1\. Granular Component Analysis** Instead of treating an email as a single block of text, the system breaks every email down into a specific "schema." It analyzes individual components such as:

• **Subject Lines & Hooks:** Identifying exactly how the email opens.

• **Messaging Categories:** Classifying the body copy, curiosity statements, and social proof used.

• **Call to Action (CTA):** Determining the specific type of ask being made.

**2\. ICP-Specific Optimization** The system correlates these specific components with performance data (meetings generated and email-to-lead ratios) for specific **Ideal Customer Profiles (ICPs)**.

• _Example Logic:_ The AI calculates "what are all of the things in the copy that are going to need to be in there in order to give us the highest multiplier on campaign efficacy" for a specific target, such as a Director of Marketing at a paper manufacturing company.

**3\. Automated Assembly** Currently, the system acts as an advisor, generating an executive summary that says, _"Hey for this ICP, this type of subject lines are winning... here's what we should do next"_.

• **The Future Step:** The goal is for the system to take that recommendation and simply **do it**. Instead of waiting for a human to build the campaign, the system would use its data to automatically select the best-performing subject line, hook, and body copy for that specific audience and launch the campaign programmatically.

The creators describe this fully automated capability as something they are "putting together" and hoping to achieve "very very soon",.

Can the AI identify winning hooks for different industries?

Yes, the AI system is specifically designed to identify winning hooks and strategies for different industries (referred to as Ideal Customer Profiles or ICPs).

It achieves this through the following process:

• **Schema Matching:** The system does not treat emails as simple text; instead, it "matches it to a schema" to isolate specific variables, explicitly analyzing the **"hook type"** along with subject lines, curiosity statements, and body messaging categories.

• **ICP Categorization:** It categorizes the Ideal Customer Profile (ICP) for every client to differentiate between audiences.

• **Performance Correlation:** It analyzes historical data to determine which specific hooks and copy elements provide the "highest multiplier on campaign efficacy" for specific roles. For example, it seeks to identify exactly what copy is required to target a **"director of marketing at a paper manufacturing company"**.

• **Actionable Reporting:** The system generates an executive summary that reports findings such as, _"Hey for this ICP this type of subject lines \[or hooks\] are winning... here's what we should do next"_.

